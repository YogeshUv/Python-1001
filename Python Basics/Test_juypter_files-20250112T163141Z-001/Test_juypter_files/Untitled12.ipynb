{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8686c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f63f827c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cx_Oracle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cx_Oracle' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "table = 'hz_locations'\n",
    "# Source database connection\n",
    "source_conn = cx_Oracle.connect(\n",
    "    user=\"apps\",\n",
    "    password=\"apps\",\n",
    "    dsn=\"csebsd2db.cswg.com:1521/csebsd2_int\"\n",
    ")\n",
    "source_cursor = source_conn.cursor()\n",
    "\n",
    "# Create a cursor\n",
    "\n",
    "# Execute a SQL query to retrieve column information\n",
    "query = f\"\"\"\n",
    "SELECT *\n",
    "FROM apps.{table}  \n",
    "\"\"\"\n",
    "\n",
    "source_cursor.execute(query)\n",
    "df = source_cursor.fetchall()\n",
    "\n",
    "# Create a DataFrame from the fetched data\n",
    "df = pd.DataFrame(df, columns=[desc[0] for desc in source_cursor.description])\n",
    "\n",
    "\n",
    "# Display the data\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7d3388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Write the DataFrame to a Parquet file\n",
    "df.to_parquet(f'{table}.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32568b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Size: 14650.73 KB\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path of the Parquet file\n",
    "file_path = f'{table}.parquet'\n",
    "# Get the file size in bytes\n",
    "file_size_bytes = os.path.getsize(file_path)\n",
    "# Convert the file size to kilobytes (KB)\n",
    "file_size_kb = file_size_bytes / 1024\n",
    "# Print the file size in KB\n",
    "print(f'File Size: {file_size_kb:.2f} KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b515772b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Read from Parquet:\n",
      "        LOCATION_ID    LAST_UPDATE_DATE  LAST_UPDATED_BY       CREATION_DATE  \\\n",
      "0             81983 2019-07-26 14:48:28            18844 2015-11-09 13:55:52   \n",
      "1             82295 2015-11-09 16:46:57             1292 2015-11-09 16:46:57   \n",
      "2             82296 2015-11-09 16:46:57             1292 2015-11-09 16:46:57   \n",
      "3             82297 2015-11-09 16:46:57             1292 2015-11-09 16:46:57   \n",
      "4             82298 2015-11-09 16:46:57             1292 2015-11-09 16:46:57   \n",
      "...             ...                 ...              ...                 ...   \n",
      "442172       304842 2017-10-30 23:20:17             1293 2017-10-30 23:20:17   \n",
      "442173       304843 2017-10-30 23:20:17             1293 2017-10-30 23:20:17   \n",
      "442174       304844 2017-10-30 23:20:17             1293 2017-10-30 23:20:17   \n",
      "442175       304845 2017-10-30 23:20:17             1293 2017-10-30 23:20:17   \n",
      "442176       304846 2017-10-30 23:20:17             1293 2017-10-30 23:20:17   \n",
      "\n",
      "        CREATED_BY  LAST_UPDATE_LOGIN  REQUEST_ID  PROGRAM_APPLICATION_ID  \\\n",
      "0             3853                 -1         NaN                     NaN   \n",
      "1             1292           15163179  15322772.0                 20008.0   \n",
      "2             1292           15163179  15322772.0                 20008.0   \n",
      "3             1292           15163179  15322772.0                 20008.0   \n",
      "4             1292           15163179  15322772.0                 20008.0   \n",
      "...            ...                ...         ...                     ...   \n",
      "442172        1293           33407313  32658908.0                 20008.0   \n",
      "442173        1293           33407313  32658908.0                 20008.0   \n",
      "442174        1293           33407313  32658908.0                 20008.0   \n",
      "442175        1293           33407313  32658908.0                 20008.0   \n",
      "442176        1293           33407313  32658908.0                 20008.0   \n",
      "\n",
      "        PROGRAM_ID PROGRAM_UPDATE_DATE  ... OBJECT_VERSION_NUMBER  \\\n",
      "0              NaN                 NaT  ...                    10   \n",
      "1          89331.0 2015-11-09 16:46:57  ...                     1   \n",
      "2          89331.0 2015-11-09 16:46:57  ...                     1   \n",
      "3          89331.0 2015-11-09 16:46:57  ...                     1   \n",
      "4          89331.0 2015-11-09 16:46:57  ...                     1   \n",
      "...            ...                 ...  ...                   ...   \n",
      "442172     89331.0 2017-10-30 23:20:17  ...                     1   \n",
      "442173     89331.0 2017-10-30 23:20:17  ...                     1   \n",
      "442174     89331.0 2017-10-30 23:20:17  ...                     1   \n",
      "442175     89331.0 2017-10-30 23:20:17  ...                     1   \n",
      "442176     89331.0 2017-10-30 23:20:17  ...                     1   \n",
      "\n",
      "       CREATED_BY_MODULE APPLICATION_ID TIMEZONE_ID GEOMETRY_STATUS_CODE  \\\n",
      "0                HZ_CPUI          222.0         2.0                DIRTY   \n",
      "1                HZ_CPUI            NaN         1.0                DIRTY   \n",
      "2                HZ_CPUI            NaN         1.0                DIRTY   \n",
      "3                HZ_CPUI            NaN         2.0                DIRTY   \n",
      "4                HZ_CPUI            NaN         2.0                DIRTY   \n",
      "...                  ...            ...         ...                  ...   \n",
      "442172           HZ_CPUI            NaN         1.0                DIRTY   \n",
      "442173           HZ_CPUI            NaN         1.0                DIRTY   \n",
      "442174           HZ_CPUI            NaN         2.0                DIRTY   \n",
      "442175           HZ_CPUI            NaN         1.0                DIRTY   \n",
      "442176           HZ_CPUI            NaN         1.0                DIRTY   \n",
      "\n",
      "       ACTUAL_CONTENT_SOURCE VALIDATION_STATUS_CODE DATE_VALIDATED  \\\n",
      "0               USER_ENTERED                   None           None   \n",
      "1               USER_ENTERED                   None           None   \n",
      "2               USER_ENTERED                   None           None   \n",
      "3               USER_ENTERED                   None           None   \n",
      "4               USER_ENTERED                   None           None   \n",
      "...                      ...                    ...            ...   \n",
      "442172          USER_ENTERED                   None           None   \n",
      "442173          USER_ENTERED                   None           None   \n",
      "442174          USER_ENTERED                   None           None   \n",
      "442175          USER_ENTERED                   None           None   \n",
      "442176          USER_ENTERED                   None           None   \n",
      "\n",
      "       DO_NOT_VALIDATE_FLAG GEOMETRY_SOURCE  \n",
      "0                      None            None  \n",
      "1                      None            None  \n",
      "2                      None            None  \n",
      "3                      None            None  \n",
      "4                      None            None  \n",
      "...                     ...             ...  \n",
      "442172                 None            None  \n",
      "442173                 None            None  \n",
      "442174                 None            None  \n",
      "442175                 None            None  \n",
      "442176                 None            None  \n",
      "\n",
      "[442177 rows x 115 columns]\n",
      "Wall time: 2.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read data from the Parquet file\n",
    "df_read = pd.read_parquet(f'{table}.parquet')\n",
    "# df_read['date_column'] =df_read['date_column'].astype('datetime64[s]')\n",
    "# # Read data from the Parquet file using Arrow\n",
    "# table = pq.read_table(f'{table}.parquet')\n",
    "# df_read = table.to_pandas()\n",
    "\n",
    "# table = pq.read_table(f'{table}.parquet')\n",
    "# df_read = table.to_pandas()\n",
    "\n",
    "print(\"\\nDataFrame Read from Parquet:\")\n",
    "print(df_read)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2c234e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import pyarrow.parquet as pq\n",
    "# import pandas as pd\n",
    "\n",
    "# # Read the Parquet files into Arrow tables\n",
    "# trans_table = pq.read_table('ar_trans_grp_agv.parquet')\n",
    "# setup_table = pq.read_table('ar_setup_grp_agv.parquet')\n",
    "\n",
    "# # Convert the Arrow tables to PaArrowInvalid: Casting from timestamp[us] to timestamp[ns] would result in out of bounds timestamp: 142508592000000000ndas DataFrames\n",
    "# df1 = trans_table.to_pandas()\n",
    "# df2 = setup_table.to_pandas()\n",
    "\n",
    "# # Merge the two DataFrames, if needed\n",
    "# merged_df = pd.concat([df1, df2], axis=0)\n",
    "# print(merged_df)\n",
    "# # Now you have a single DataFrame that contains the data from both Parquet files\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
