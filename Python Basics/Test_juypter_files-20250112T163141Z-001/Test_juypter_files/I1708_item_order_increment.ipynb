{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc0c1a62",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_csv() got an unexpected keyword argument 'sheet_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b580680ca13f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Read the first sheet of the Excel file into a DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexcel_file_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msheet_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# 'df' is now a dictionary where keys are sheet names, and values are DataFrames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: read_csv() got an unexpected keyword argument 'sheet_name'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your Excel file\n",
    "excel_file_path = 'D:\\W\\RELEX\\RELEX\\I1708 – CSPOMS Item Order Increment Updates\\Item_Order_Increment_080220241537.csv'\n",
    "\n",
    "# Read the first sheet of the Excel file into a DataFrame\n",
    "df = pd.read_csv(excel_file_path,sheet_name = None)\n",
    "\n",
    "# 'df' is now a dictionary where keys are sheet names, and values are DataFrames\n",
    "# Access the first sheet by taking the first item in the dictionary\n",
    "first_sheet_name = list(df.keys())[0]\n",
    "first_sheet_df = df[first_sheet_name]\n",
    "\n",
    "# Now, 'first_sheet_df' contains the data from the first sheet of the Excel file\n",
    "print(first_sheet_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc90a719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SSIC  FACILITY  INCREMENT MULTIPLE\n",
      "0   122180        97                  13\n",
      "1   122177        78                  13\n",
      "2   122177        14                  13\n",
      "3   122176        36                  13\n",
      "4   122178        36                  13\n",
      "5   122178        14                  13\n",
      "6   122176        18                  13\n",
      "7   122178        96                  13\n",
      "8   122176        43                  13\n",
      "9   122179        14                  13\n",
      "10  122180        67                  13\n",
      "11  122179        44                  13\n",
      "12  122177        43                  13\n",
      "13  122176        14                  13\n",
      "14  122178        43                  13\n",
      "15  122180        46                  13\n",
      "16  122178        44                  13\n",
      "17  122180        44                  13\n",
      "18   35054        18                  13\n",
      "19  122178        67                  13\n",
      "20  122176        44                  13\n",
      "21  122180        14                  13\n",
      "22  122177        67                  13\n",
      "23  122177        84                  13\n",
      "24  232751        18                  13\n",
      "25  122177        44                  13\n",
      "26  301750        18                  13\n",
      "27  122176        46                  13\n",
      "28  122180        96                  13\n",
      "29   39615        18                  13\n",
      "30  122177        18                  13\n",
      "31  122178        18                  13\n",
      "32  122180        43                  13\n",
      "33  403040        44                  13\n",
      "34  122177        36                  13\n",
      "35  122176        96                  13\n",
      "36  433334        18                  13\n",
      "37  122180        18                  13\n",
      "38  122180        36                  13\n",
      "39  433334        46                  13\n",
      "40  122177        96                  13\n",
      "41  122176        78                  13\n",
      "42  122176        67                  13\n",
      "43  403040        14                  13\n",
      "INSERTED 44 EXCEL RECORDS TO cspoms.XXPO_ITEM_UPLOAD_DETAILS_STG TABLE\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_file_path = 'D:\\\\W\\\\RELEX\\\\RELEX\\\\I1708 – CSPOMS Item Order Increment Updates\\\\Item_Order_Increment_080220241537.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Now, 'df' contains the data from the CSV file\n",
    "print(df)\n",
    "# Specify the table name\n",
    "table_name = 'cspoms.XXPO_ITEM_UPLOAD_DETAILS_STG'\n",
    "\n",
    "# Convert the DataFrame to a list of tuples for bulk insertion\n",
    "data_tuples = [tuple(row) for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "# Define the PostgreSQL INSERT statement\n",
    "insert_query = f\"INSERT INTO {table_name} (ssic, facility, increment_multiple) VALUES (%s, %s, %s)\"\n",
    "\n",
    "# Execute the INSERT statement with the data\n",
    "post_cur.executemany(insert_query, data_tuples)\n",
    "count = post_cur.rowcount\n",
    "post_conn.commit()\n",
    "\n",
    "print(f'INSERTED {count} EXCEL RECORDS TO {table_name} TABLE')\n",
    "\n",
    "post_cur.execute('''UPDATE XXPO_ITEM_UPLOAD_DETAILS_STG\n",
    "SET process_status = 'E', process_message = 'Duplicate Record'\n",
    "WHERE (facility, ssic) IN (\n",
    "    SELECT facility, ssic\n",
    "    FROM XXPO_ITEM_UPLOAD_DETAILS_STG\n",
    "    GROUP BY facility, ssic\n",
    "    HAVING COUNT(*) > 1\n",
    ")\n",
    "''')\n",
    "duplicate_count = post_cur.rowcount\n",
    "print(duplicate_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7ddae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34d780a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SSIC  Facility  Increment Multiple    PROCESS_MESSAGE PROCESS_STATUS\n",
      "0   123         1                  10  Records duplicate              E\n",
      "1   456         2                   5  Records duplicate              E\n",
      "2   789         3                  25  Records duplicate              E\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'first_sheet_df' is your DataFrame\n",
    "df = first_sheet_df.copy()  # Make a copy to avoid modifying the original DataFrame\n",
    "\n",
    "# Identify duplicate rows based on 'SSIC' and 'Facility' columns\n",
    "duplicate_mask = df.duplicated(subset=['SSIC', 'Facility'], keep=False)\n",
    "\n",
    "# Add 'PROCESS_MESSAGE' and 'PROCESS_STATUS' columns\n",
    "df['PROCESS_MESSAGE'] = 'Records duplicate'\n",
    "df['PROCESS_STATUS'] = 'E'\n",
    "\n",
    "# Update the 'PROCESS_STATUS' and 'PROCESS_MESSAGE' columns for duplicate rows\n",
    "df.loc[duplicate_mask, ['PROCESS_STATUS', 'PROCESS_MESSAGE']] = ['E', 'Records duplicate']\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n",
    "\n",
    "duplicate_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0ce6418",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'itertuples'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ff210865070b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m# Convert the DataFrame to a list of tuples for bulk insertion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mdata_tuples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m# Define the PostgreSQL INSERT statement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'itertuples'"
     ]
    }
   ],
   "source": [
    "# Broker_vendor.py\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "import re\n",
    "import cx_Oracle\n",
    "# Database connection parameters\n",
    "db_params = {\n",
    "    \"host\": \"gc-ue4-psql-cspo-dev01.nonprod.gcp.cswg.com\",\n",
    "    \"database\": \"CSPODB\",\n",
    "    \"port\": 5432,\n",
    "    \"user\": \"cspoms\",\n",
    "    \"password\": \"cspoms\",\n",
    "    \"sslmode\": \"verify-ca\",\n",
    "    \"sslcert\": \"D:\\\\W\\\\RELEX\\\\RELEX\\\\CSPOMS_DEV_Conn\\\\client-cert.pem\",\n",
    "    \"sslkey\": \"D:\\\\W\\\\RELEX\\\\RELEX\\\\CSPOMS_DEV_Conn\\\\client-key.pem\",\n",
    "    \"sslrootcert\": \"D:\\\\W\\\\RELEX\\\\RELEX\\\\CSPOMS_DEV_Conn\\\\server-ca.pem\"\n",
    "}\n",
    "\n",
    "post_conn = psycopg2.connect(**db_params)\n",
    "post_cur = post_conn.cursor()\n",
    "########################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################\n",
    "# Specify the path to your Excel file\n",
    "excel_file_path = 'D:\\W\\RELEX\\RELEX\\I1708 – CSPOMS Item Order Increment Updates\\Test_file2.xlsx'\n",
    "\n",
    "# Read the first sheet of the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file_path,sheet_name = None)\n",
    "\n",
    "# 'df' is now a dictionary where keys are sheet names, and values are DataFrames\n",
    "# Access the first sheet by taking the first item in the dictionary\n",
    "first_sheet_name = list(df.keys())[0]\n",
    "first_sheet_df = df[first_sheet_name]\n",
    "\n",
    "# Specify the table name\n",
    "table_name = 'cspoms.XXPO_ITEM_UPLOAD_DETAILS_STG'\n",
    "\n",
    "# Convert the DataFrame to a list of tuples for bulk insertion\n",
    "data_tuples = [tuple(row) for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "# Define the PostgreSQL INSERT statement\n",
    "insert_query = f\"INSERT INTO {table_name} (item_ssic, org_code,increment_multiple) VALUES (%s, %s, %s)\"\n",
    "\n",
    "# Execute the INSERT statement with the data\n",
    "post_cur.executemany(insert_query, data_tuples)\n",
    "count = post_cur.rowcount\n",
    "post_conn.commit()\n",
    "\n",
    "print(f'INSERTED {count} EXCEL RECORDS TO {table_name} TABLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49b47eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sheet1':    SSIC  Facility  Increment Multiple\n",
       " 0   123         1                  10\n",
       " 1   456         2                   5\n",
       " 2   789         3                  25}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
